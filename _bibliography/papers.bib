@article{singha2021deep,
  title={Deep learning applications in medical image analysis},
  author={Singha, Ananya and Thakur, Rini Smita and Patel, Tushar},
  journal={Biomedical Data Mining for Information Retrieval: Methodologies, Techniques and Applications},
  pages={293--350},
  year={2021},
  publisher={Wiley Online Library},
selected = {true}
}

@article{singha2023tabular,
  title={Tabular representation, noisy operators, and impacts on table structure understanding tasks in llms},
  author={Singha, Ananya and Cambronero, Jos{\'e} and Gulwani, Sumit and Le, Vu and Parnin, Chris},
  journal={arXiv preprint arXiv:2310.10358},
  year={2023},
  selected = {true},
    award = {Best Paper Runner-Up Award, Spotlight paper},
  award_name = {Best Paper Runner-Up Award, Spotlight paper},
  abstract = {Large language models (LLMs) are increasingly applied for tabular tasks using in-context learning. The prompt representation for a table may play a role in the LLMs ability to process the table. Inspired by prior work, we generate a collection of self-supervised structural tasks (e.g. navigate to a cell and row; transpose the table) and evaluate the performance differences when using 8 formats. In contrast to past work, we introduce 8 noise operations inspired by real-world messy data and adversarial inputs, and show that such operations can impact LLM performance across formats for different structural understanding tasks.}
}

@inproceedings{
anonymous2024metareflection,
title={MetaReflection: Learning Instructions for Language Agents using Past Reflections},
author={Singha*, Ananya and Gupta*, Priyanshu and Kirtania*, Shashank and Gulwani, Sumit and Radhakrishna, Arjun and Shi, Sherry and Soares, Gustavo},
booktitle={The 2024 Conference on Empirical Methods in Natural Language Processing},
year={2024},
url={https://openreview.net/forum?id=TuNSww753I},
selected = {true},
annotation={* Equal Contribution},
abstract = {The popularity of Large Language Models (LLMs) have unleashed a new age of Language Agents for solving a diverse range of tasks. While contemporary frontier LLMs are capable enough to power reasonably good Language agents, the closed-API model makes it hard to improve in cases they perform sub-optimally. To address this, recent works have explored techniques to improve their performance using self reflection and prompt optimization techniques. While techniques like self reflection work well in an online setup, contemporary prompt optimization techniques are designed to work on simpler tasks. To address this, we introduce METAREFLECTION, a novel offline reinforcement learning technique that enhances the performance of Language Agents by augmenting a semantic memory based on experiential learnings from past trials. We demonstrate the efficacy of METAREFLECTION by evaluating across multiple domains, including complex logical reasoning, biomedical semantic similarity, open world question answering, and vulnerability threat detection, in Infrastructure-as-Code, with different agent design. METAREFLECTION boosts Language agentsâ€™ performance by 4 % to 16.82 % over the raw GPT-4 baseline and performs on par with existing state-of-the-art prompt optimization techniques while requiring fewer LLM calls.}
}

@inproceedings{singha2024semantically,
  title={Semantically Aligned Question and Code Generation for Automated Insight Generation},
  author={Singha, Ananya and Chopra, Bhavya and Khatry, Anirudh and Gulwani, Sumit and Henley, Austin and Le, Vu and Parnin, Chris and Singh, Mukul and Verbruggen, Gust},
  booktitle={Proceedings of the 1st International Workshop on Large Language Models for Code},
  pages={127--134},
  year={2024},
    award= {Best Paper Award},
  award_name = {Best Paper Award},
selected = {true},
abstract = {Automated insight generation is a common tactic for helping knowledge workers, such as data scientists, to quickly understand the potential value of new and unfamiliar data. Unfortunately, automated insights produced by large-language models can generate code that does not correctly correspond (or align) to the insight. In this paper, we leverage the semantic knowledge of large language models to generate targeted and insightful questions about data and the corresponding code to answer those questions. Then through an empirical study on data from Open-WikiTable, we show that embeddings can be effectively used for filtering out semantically unaligned pairs of question and code. Additionally, we found that generating questions and code together yields more diverse questions.}
}

@inproceedings{khatry2023tstr,
  title={TSTR: Target Similarity Tuning Meets the Real World},
  author={Khatry, Anirudh and Gulwani, Sumit and Gupta, Priyanshu and Le, Vu and Singh, Mukul and Singha, Ananya and Verbruggen, Gust},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2023},
  pages={10256--10261},
  year={2023},
  selected = {true},
  abstract = {Target similarity tuning (TST) is a method of selecting relevant examples in natural language (NL) to code generation through large language models (LLMs) to improve performance. Its goal is to adapt a sentence embedding model to have the similarity between two NL inputs match the similarity between their associated code outputs. In this paper, we propose different methods to apply and improve TST in the real world. First, we replace the sentence transformer with embeddings from a larger model, which reduces sensitivity to the language distribution and thus provides more flexibility in synthetic generation of examples, and we train a tiny model that transforms these embeddings to a space where embedding similarity matches code similarity, which allows the model to remain a black box and only requires a few matrix multiplications at inference time. Second, we how to efficiently select a smaller number of training examples to train the TST model. Third, we introduce a ranking-based evaluation for TST that does not require end-to-end code generation experiments, which can be expensive to perform.}
}

@article{chopra2023conversational,
  title={Conversational challenges in ai-powered data science: Obstacles, needs, and design opportunities},
  author={Chopra, Bhavya and Singha, Ananya and Fariha, Anna and Gulwani, Sumit and Parnin, Chris and Tiwari, Ashish and Henley, Austin Z},
  journal={arXiv preprint arXiv:2310.16164},
  year={2023},
  selected = {true},
  abstract = {Large Language Models (LLMs) are being increasingly employed in data science for tasks like data preprocessing and analytics. However, data scientists encounter substantial obstacles when conversing with LLM-powered chatbots and acting on their suggestions and answers. We conducted a mixed-methods study, including contextual observations, semi-structured interviews (n=14), and a survey (n=114), to identify these challenges. Our findings highlight key issues faced by data scientists, including contextual data retrieval, formulating prompts for complex tasks, adapting generated code to local environments, and refining prompts iteratively. Based on these insights, we propose actionable design recommendations, such as data brushing to support context selection, and inquisitive feedback loops to improve communications with AI-based assistants in data-science tools.}
}
